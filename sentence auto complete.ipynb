{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19958,"status":"ok","timestamp":1713700191850,"user":{"displayName":"Sahith Patchigalla","userId":"01732042447938544610"},"user_tz":-330},"id":"jrkFO1W5nXRz","outputId":"e7ddde57-f75c-4765-d20d-f9202782b38e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting datasets\n","  Downloading datasets-2.19.0-py3-none-any.whl (542 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n","Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n","Collecting huggingface-hub>=0.21.2 (from datasets)\n","  Downloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Installing collected packages: xxhash, dill, multiprocess, huggingface-hub, datasets\n","  Attempting uninstall: huggingface-hub\n","    Found existing installation: huggingface-hub 0.20.3\n","    Uninstalling huggingface-hub-0.20.3:\n","      Successfully uninstalled huggingface-hub-0.20.3\n","Successfully installed datasets-2.19.0 dill-0.3.8 huggingface-hub-0.22.2 multiprocess-0.70.16 xxhash-3.4.1\n"]}],"source":["!pip install datasets\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":78588,"status":"ok","timestamp":1713700270432,"user":{"displayName":"Sahith Patchigalla","userId":"01732042447938544610"},"user_tz":-330},"id":"ifxqDsDEnrvG","outputId":"3aec702c-12d2-4950-d4d6-7ef70b3a9cf7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torchtext in /usr/local/lib/python3.10/dist-packages (0.17.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext) (4.66.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.31.0)\n","Requirement already satisfied: torch==2.2.1 in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.2.1+cu121)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext) (1.25.2)\n","Requirement already satisfied: torchdata==0.7.1 in /usr/local/lib/python3.10/dist-packages (from torchtext) (0.7.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchtext) (3.13.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchtext) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchtext) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchtext) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchtext) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchtext) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.1->torchtext)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.1->torchtext)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.1->torchtext)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.1->torchtext)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.1->torchtext)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.1->torchtext)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.1->torchtext)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.1->torchtext)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.1->torchtext)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.1->torchtext)\n","  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.1->torchtext)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchtext) (2.2.0)\n","Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.7.1->torchtext) (2.0.7)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.1->torchtext)\n","  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2024.2.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.2.1->torchtext) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.1->torchtext) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n"]}],"source":["!pip install torchtext"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12333,"status":"ok","timestamp":1713700282754,"user":{"displayName":"Sahith Patchigalla","userId":"01732042447938544610"},"user_tz":-330},"id":"qBGSfwyRaRtG","outputId":"1616e6fa-05ab-4434-ef29-17c62a7cacd4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting docx2txt\n","  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: docx2txt\n","  Building wheel for docx2txt (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3960 sha256=60923b2a1b7df0656cdadad82eff1ea936a0d75cdb5800c9dba4e8e088fce4ff\n","  Stored in directory: /root/.cache/pip/wheels/22/58/cf/093d0a6c3ecfdfc5f6ddd5524043b88e59a9a199cb02352966\n","Successfully built docx2txt\n","Installing collected packages: docx2txt\n","Successfully installed docx2txt-0.8\n"]}],"source":["!pip install docx2txt\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":79283,"status":"ok","timestamp":1713700362034,"user":{"displayName":"Sahith Patchigalla","userId":"01732042447938544610"},"user_tz":-330},"id":"GOS4GYFPprRq","outputId":"120f5978-50c9-40f0-c0b3-4c4beabfeda6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torchtext in /usr/local/lib/python3.10/dist-packages (0.17.1)\n","Collecting torchtext\n","  Downloading torchtext-0.17.2-cp310-cp310-manylinux1_x86_64.whl (2.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext) (4.66.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.31.0)\n","Collecting torch==2.2.2 (from torchtext)\n","  Downloading torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext) (1.25.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->torchtext) (3.13.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->torchtext) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->torchtext) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->torchtext) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->torchtext) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->torchtext) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->torchtext) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->torchtext) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->torchtext) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->torchtext) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->torchtext) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->torchtext) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->torchtext) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->torchtext) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->torchtext) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->torchtext) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->torchtext) (12.1.105)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->torchtext) (2.2.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.2->torchtext) (12.4.127)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2024.2.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.2.2->torchtext) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.2->torchtext) (1.3.0)\n","Installing collected packages: torch, torchtext\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.2.1+cu121\n","    Uninstalling torch-2.2.1+cu121:\n","      Successfully uninstalled torch-2.2.1+cu121\n","  Attempting uninstall: torchtext\n","    Found existing installation: torchtext 0.17.1\n","    Uninstalling torchtext-0.17.1:\n","      Successfully uninstalled torchtext-0.17.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchaudio 2.2.1+cu121 requires torch==2.2.1, but you have torch 2.2.2 which is incompatible.\n","torchvision 0.17.1+cu121 requires torch==2.2.1, but you have torch 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed torch-2.2.2 torchtext-0.17.2\n"]}],"source":["!pip install --upgrade torchtext\n"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14012,"status":"ok","timestamp":1713700376033,"user":{"displayName":"Sahith Patchigalla","userId":"01732042447938544610"},"user_tz":-330},"id":"w4IoQQZEK_i5","outputId":"e772b163-4f11-4dec-cb5d-acc6aaa6db6d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting python-docx==0.8.10\n","  Downloading python-docx-0.8.10.tar.gz (5.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: lxml>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from python-docx==0.8.10) (4.9.4)\n","Building wheels for collected packages: python-docx\n","  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for python-docx: filename=python_docx-0.8.10-py3-none-any.whl size=184379 sha256=ef8fdfd81eac5d3e62c8ede143b37116532adfae2334b5e123d7efe19a07072c\n","  Stored in directory: /root/.cache/pip/wheels/a3/8f/1a/a58b6ebe13e7c0681fa2367ce7300f8bb2c538cad7a29ff50d\n","Successfully built python-docx\n","Installing collected packages: python-docx\n","Successfully installed python-docx-0.8.10\n"]}],"source":["!pip install python-docx==0.8.10\n"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1491,"status":"ok","timestamp":1713701166941,"user":{"displayName":"Sahith Patchigalla","userId":"01732042447938544610"},"user_tz":-330},"id":"xuE_hg9OSVyT","outputId":"48e39ec2-a8dd-440e-d6d5-3b38fe9943d0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Text data cleaned and saved to: /content/Crime-and-Punishment-.csv\n"]}],"source":["import re\n","import string\n","import pandas as pd\n","import docx2txt\n","\n","doc_path = \"/content/Crime-and-Punishment-.docx\"\n","text_data = docx2txt.process(doc_path)\n","text_data = text_data.lower()\n","text_data = re.sub(r\"\\[.*?\\]\", \"\", text_data)\n","\n","english_alphabet = set(string.ascii_lowercase)\n","text_data = ' '.join([word for word in text_data.split() if all(char in english_alphabet for char in word)])\n","text_data = text_data.strip()\n","text_data = [text for text in text_data.split('\\n') if text.strip()]\n","\n","df = pd.DataFrame({\"Text\": text_data})\n","\n","output_path = \"/content/Crime-and-Punishment-.csv\"\n","df.to_csv(output_path, index=False)\n","\n","print(\"Text data cleaned and saved to:\", output_path)\n","\n","\n"]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","import pandas as pd\n","from collections import Counter\n","from torch import nn\n","from torch.utils.data import DataLoader, random_split\n","from torch.nn.utils.rnn import pad_sequence\n","\n","class TextDataset(torch.utils.data.Dataset):\n","    def __init__(self, sequence_length, csv_file_path):\n","        self.sequence_length = sequence_length\n","        self.words = self.load_words(csv_file_path)\n","        self.unique_words = self.get_unique_words()\n","\n","        self.index_to_word = {index: word for index, word in enumerate(self.unique_words)}\n","        self.word_to_index = {word: index for index, word in enumerate(self.unique_words)}\n","\n","        # Add <UNK> token to word_to_index mapping\n","        self.word_to_index['<UNK>'] = len(self.unique_words)\n","\n","        self.word_indexes = [self.word_to_index.get(w, self.word_to_index['<UNK>']) for w in self.words]\n","\n","    def load_words(self, csv_file_path):\n","        train_df = pd.read_csv(csv_file_path)\n","        text = train_df['Text'].str.cat(sep=' ')\n","        return text.split(' ')\n","\n","    def get_unique_words(self):\n","        word_counts = Counter(self.words)\n","        return sorted(word_counts, key=word_counts.get, reverse=True)\n","\n","    def __len__(self):\n","        return len(self.word_indexes) - self.sequence_length + 1\n","\n","    def __getitem__(self, index):\n","        input_sequence = torch.tensor(self.word_indexes[index:index + self.sequence_length])\n","        target_sequence = torch.tensor(self.word_indexes[index + 1:index + self.sequence_length + 1])\n","        return input_sequence, target_sequence\n"],"metadata":{"id":"gBdCyL9K13mZ","executionInfo":{"status":"ok","timestamp":1713703837303,"user_tz":-330,"elapsed":3840,"user":{"displayName":"Sahith Patchigalla","userId":"01732042447938544610"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["class LSTMModel(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers):\n","        super(LSTMModel, self).__init__()\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first=True)\n","        self.fc = nn.Linear(hidden_dim, vocab_size)\n","\n","    def forward(self, x):\n","        embedded = self.embedding(x)\n","        output, _ = self.lstm(embedded)\n","        output = self.fc(output)\n","        return output\n","\n","# Load and preprocess your data using TextDataset\n","sequence_length = 10\n","csv_file_path = '/content/Crime-and-Punishment-.csv'\n","dataset = TextDataset(sequence_length, csv_file_path)\n","\n","# Create DataLoader for batch processing\n","batch_size = 64\n","train_size = int(0.8 * len(dataset))\n","val_size = len(dataset) - train_size\n","train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n","\n","def collate_batch(batch):\n","    inputs = [item[0] for item in batch]\n","    targets = [item[1] for item in batch]\n","\n","    # Pad sequences to the maximum length in the batch\n","    max_length = max([len(seq) for seq in inputs])\n","    padded_inputs = [torch.cat([seq, torch.zeros(max_length - len(seq), dtype=torch.long)]) for seq in inputs]\n","    padded_targets = [torch.cat([seq, torch.zeros(max_length - len(seq), dtype=torch.long)]) for seq in targets]\n","\n","    return torch.stack(padded_inputs), torch.stack(padded_targets)\n","\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, collate_fn=collate_batch)\n","\n","# Initialize your language model\n","vocab_size = len(dataset.unique_words)\n","embedding_dim = 100\n","hidden_dim = 256\n","num_layers = 2\n","model = LSTMModel(vocab_size, embedding_dim, hidden_dim, num_layers)\n","\n","# Training loop\n","learning_rate = 0.001\n","num_epochs = 8\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    total_loss = 0.0\n","\n","    for batch in train_loader:\n","        inputs, targets = batch\n","\n","        optimizer.zero_grad()\n","\n","        outputs = model(inputs)\n","\n","        outputs_flat = outputs.view(-1, len(dataset.unique_words))\n","        targets_flat = targets.view(-1)\n","\n","        loss = criterion(outputs_flat, targets_flat)\n","        loss.backward()\n","\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","\n","    average_loss = total_loss / len(train_loader)\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Average Loss: {average_loss:.4f}\")\n","\n","    model.eval()\n","    val_loss = 0.0\n","\n","    with torch.no_grad():\n","        for batch in val_loader:\n","            inputs, targets = batch\n","\n","            outputs = model(inputs)\n","\n","            outputs_flat = outputs.view(-1, len(dataset.unique_words))\n","            targets_flat = targets.view(-1)\n","\n","            loss = criterion(outputs_flat, targets_flat)\n","            val_loss += loss.item()\n","\n","    average_val_loss = val_loss / len(val_loader)\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {average_val_loss:.4f}\")"],"metadata":{"id":"05L-ImtCCuLw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713709643147,"user_tz":-330,"elapsed":5803478,"user":{"displayName":"Sahith Patchigalla","userId":"01732042447938544610"}},"outputId":"9e453666-ed3d-4499-c3e9-0aa56843bcec"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/8], Average Loss: 5.7103\n","Epoch [1/8], Validation Loss: 5.0943\n","Epoch [2/8], Average Loss: 4.7398\n","Epoch [2/8], Validation Loss: 4.4402\n","Epoch [3/8], Average Loss: 4.0849\n","Epoch [3/8], Validation Loss: 3.8928\n","Epoch [4/8], Average Loss: 3.5186\n","Epoch [4/8], Validation Loss: 3.4506\n","Epoch [5/8], Average Loss: 3.0653\n","Epoch [5/8], Validation Loss: 3.1037\n","Epoch [6/8], Average Loss: 2.7059\n","Epoch [6/8], Validation Loss: 2.8280\n","Epoch [7/8], Average Loss: 2.4151\n","Epoch [7/8], Validation Loss: 2.6055\n","Epoch [8/8], Average Loss: 2.1790\n","Epoch [8/8], Validation Loss: 2.4253\n"]}]},{"cell_type":"code","source":["input_sentence = \"the landlady who provided\"\n","input_indexes = [dataset.word_to_index.get(word, dataset.word_to_index['<UNK>'])\n","                 for word in input_sentence.split()]\n","input_tensor = torch.tensor(input_indexes,\n","                            dtype=torch.long).unsqueeze(0)\n","\n","# Generate the next words\n","model.eval()\n","hidden = None  # No need to initialize hidden state for the first input\n","predicted_sentence = input_sentence.split()\n","\n","desired_sentence_length = 3    # Define the desired length of the generated sentence\n","\n","with torch.no_grad():\n","    for _ in range(desired_sentence_length):\n","        outputs = model(input_tensor)\n","        predicted_index = torch.argmax(outputs[0, -1, :]).item()\n","        predicted_word = dataset.index_to_word.get(predicted_index, \"<UNK>\")\n","        predicted_sentence.append(predicted_word)\n","\n","        # Prepare the next input_tensor\n","        input_indexes = input_indexes[1:] + [predicted_index]  # Update input tensor by removing the first word and adding the predicted word index\n","        input_tensor = torch.tensor([input_indexes],\n","                                    dtype=torch.long)\n","\n","# Print the predicted sentence\n","print(\"Input Sentence:\", input_sentence)\n","print(\"Predicted Sentence:\", ' '.join(predicted_sentence))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-vUBEDT6j0-b","executionInfo":{"status":"ok","timestamp":1713710379936,"user_tz":-330,"elapsed":380,"user":{"displayName":"Sahith Patchigalla","userId":"01732042447938544610"}},"outputId":"28e308f1-3dac-4987-ce8e-aca0947422c8"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Input Sentence: the landlady who provided\n","Predicted Sentence: the landlady who provided him with and\n"]}]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNWL6ljwgmFLhCA4P20y0Wx"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}